.. DO NOT MODIFY: this file was automatically generated!

:orphan:

Seminar by Yanlai Chen
=================================
.. container:: sd-badge-seminar-container

    :bdg-primary-line:`Speaker`

    .. container:: sd-badge-next-text

        Yanlai Chen (University of Massachusetts Dartmouth)

    :bdg-primary-line:`Title`

    .. container:: sd-badge-next-text

        GPT-PINN: Generative Pre-Trained Physics-Informed Neural Networks toward non-intrusive Meta-learning of parametric PDEs

    :bdg-primary-line:`Date`

    .. container:: sd-badge-next-text

        * May 16, 2023 16:00 CEST+0200 (Europe/Rome)
        * May 16, 2023 10:00 EDT-0400 (US/Eastern)
        * May 16, 2023 09:00 CDT-0500 (US/Central)
        * May 16, 2023 07:00 PDT-0700 (US/Pacific)

    :bdg-primary-line:`Abstract`

    .. container:: sd-badge-next-text

        Physics-Informed Neural Network (PINN) has proven itself a powerful tool
        to obtain the numerical solutions of nonlinear partial differential
        equations (PDEs) leveraging the expressivity of deep neural networks and
        the computing power of modern heterogeneous hardware. However, its
        training is still time-consuming, especially in the multi-query and
        real-time simulation settings, and its parameterization often overly
        excessive.
        
        In this talk, we present the recently proposed Generative Pre-Trained
        PINN (GPT-PINN). It mitigates both challenges in the setting of
        parametric PDEs. GPT-PINN represents a brand-new meta-learning paradigm
        for parametric systems. As a network of networks, its
        outer-/meta-network is hyper-reduced with only one hidden layer having
        significantly reduced number of neurons. Moreover, its activation
        function at each hidden neuron is a (full) PINN pre-trained at a
        judiciously selected system configuration. The meta-network adaptively
        “learns” the parametric dependence of the system and “grows” this hidden
        layer one neuron at a time. In the end, by encompassing a very small
        number of networks trained at this set of adaptively-selected parameter
        values, the meta-network is capable of generating surrogate solutions
        for the parametric system across the entire parameter domain accurately
        and efficiently.

    :bdg-primary-line:`Recording`

    .. container:: sd-badge-next-text

        Watch the recording on `our YouTube channel <https://www.youtube.com/watch?v=KWaWH7xeVEg>`_.
    