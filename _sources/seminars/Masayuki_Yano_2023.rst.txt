.. DO NOT MODIFY: this file was automatically generated!

:orphan:

Seminar by Masayuki Yano
===============================
.. container:: sd-badge-seminar-container

    :bdg-primary-line:`Speaker`

    .. container:: sd-badge-next-text

        Masayuki Yano (University of Toronto)

    :bdg-primary-line:`Title`

    .. container:: sd-badge-next-text

        Model reduction of parametrized aerodynamics problems: error estimation, adaptivity, and nonlinear approximations

    :bdg-primary-line:`Date`

    .. container:: sd-badge-next-text

        * February 21, 2023 16:00 CET+0100 (Europe/Rome)
        * February 21, 2023 10:00 EST-0500 (US/Eastern)
        * February 21, 2023 09:00 CST-0600 (US/Central)
        * February 21, 2023 07:00 PST-0800 (US/Pacific)

    :bdg-primary-line:`Abstract`

    .. container:: sd-badge-next-text

        We present goal-oriented model reduction of parametrized nonlinear PDEs,
        with an emphasis on aerodynamics problems that exhibit a wide range of
        scales, unsteadiness, and geometry changes. The key ingredients are as
        follows: an adaptive high-order discontinuous Galerkin (DG) method,
        which provides stability for convention-dominated flows and controls
        error in the snapshots; linear and nonlinear reduced basis (RB) spaces,
        which provide rapidly convergent approximations of the parametric
        manifold; the point-wise empirical quadrature procedure (EQP), which
        provides efficient and reliable hyperreduction; the dual-weighted
        residual (DWR) method, which provides effective error estimate for both
        the DG snapshots and reduced-order model (ROM); and an adaptive weak
        greedy algorithm, which simultaneously adapts the DG spaces, RB spaces,
        and EQP to meet the user-specified output error tolerance in an
        automated manner. We demonstrate the framework for parametrized
        aerodynamics problems modeled by the compressible Euler and
        Reynolds-averaged Navier-Stokes equations. In the offline stage, the
        adaptive greedy algorithm enables efficient and automated training of
        ROMs. In the online stage, the ROMs accelerate the computation by
        several orders of magnitude and also provide a posteriori error
        estimates.

    